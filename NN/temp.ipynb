{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import all modules you will use\n",
    "import torch # pip install \n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms # pip install \n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load in the dataset\n",
    "\n",
    "pick = datasets.MNIST(root='./data', train=True, download=True)\n",
    "\n",
    "train_dataset = datasets.MNIST(root='./data', train=True, download=True, transform=transforms.ToTensor())#This specifies that we want the test part of the MNIST dataset.\n",
    "test_dataset = datasets.MNIST(root='./data', train=False, download=True, transform=transforms.ToTensor())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "image, label = pick[50] \n",
    "\n",
    "plt.imshow(image, cmap=\"gray\")\n",
    "plt.title(f\"{label}\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[[0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.2000,\n",
       "           0.6235, 0.9922, 0.6235, 0.1961, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.1882, 0.9333,\n",
       "           0.9882, 0.9882, 0.9882, 0.9294, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.2118, 0.8902, 0.9922,\n",
       "           0.9882, 0.9373, 0.9137, 0.9882, 0.2235, 0.0235, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0392, 0.2353, 0.8784, 0.9882, 0.9922,\n",
       "           0.9882, 0.7922, 0.3294, 0.9882, 0.9922, 0.4784, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.6392, 0.9882, 0.9882, 0.9882, 0.9922,\n",
       "           0.9882, 0.9882, 0.3765, 0.7412, 0.9922, 0.6549, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.2000, 0.9333, 0.9922, 0.9922, 0.7451, 0.4471,\n",
       "           0.9922, 0.8941, 0.1843, 0.3098, 1.0000, 0.6588, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.1882, 0.9333, 0.9882, 0.9882, 0.7020, 0.0471, 0.2941,\n",
       "           0.4745, 0.0824, 0.0000, 0.0000, 0.9922, 0.9529, 0.1961, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.1490, 0.6471, 0.9922, 0.9137, 0.8157, 0.3294, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000, 0.9922, 0.9882, 0.6471, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0275,\n",
       "           0.6980, 0.9882, 0.9412, 0.2784, 0.0745, 0.1098, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000, 0.9922, 0.9882, 0.7647, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.2235,\n",
       "           0.9882, 0.9882, 0.2471, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000, 0.9922, 0.9882, 0.7647, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.7765,\n",
       "           0.9922, 0.7451, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000, 1.0000, 0.9922, 0.7686, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.2980, 0.9647,\n",
       "           0.9882, 0.4392, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000, 0.9922, 0.9882, 0.5804, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.3333, 0.9882,\n",
       "           0.9020, 0.0980, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0275, 0.5294, 0.9922, 0.7294, 0.0471, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.3333, 0.9882,\n",
       "           0.8745, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0275, 0.5137, 0.9882, 0.8824, 0.2784, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.3333, 0.9882,\n",
       "           0.5686, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.1882, 0.6471, 0.9882, 0.6784, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.3373, 0.9922,\n",
       "           0.8824, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.4471,\n",
       "           0.9333, 0.9922, 0.6353, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.3333, 0.9882,\n",
       "           0.9765, 0.5725, 0.1882, 0.1137, 0.3333, 0.6980, 0.8824, 0.9922,\n",
       "           0.8745, 0.6549, 0.2196, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.3333, 0.9882,\n",
       "           0.9882, 0.9882, 0.8980, 0.8431, 0.9882, 0.9882, 0.9882, 0.7686,\n",
       "           0.5098, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.1098, 0.7804,\n",
       "           0.9882, 0.9882, 0.9922, 0.9882, 0.9882, 0.9137, 0.5686, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0980,\n",
       "           0.5020, 0.9882, 0.9922, 0.9882, 0.5529, 0.1451, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000]]]),\n",
       " 0)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data cleaning or for NN - work on transforming the data\n",
    " #Takes list of Transformations & composes them into single trans(Applied in order). Converts images into tensors. Then normalizes tensor images.\n",
    "transform = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.1307,), (0.3081,))]) \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Data Loaders on the data to make it easy to feed data to the model in batches.\n",
    "\n",
    "\n",
    "#make the data loaders\n",
    "\n",
    "# Loads data in shuffled batches of 64 samples. Reduces overfitting.\n",
    "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
    "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=64, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a class to be the NN model (must have an __init__ and a forward function)\n",
    "# init the nn class with an init function and a forward pass\n",
    "class Net(nn.Module):                      # Defines a new class Net that inherits from nn.Module\n",
    "    def __init__(self):  \n",
    "        super(Net, self).__init__()  \n",
    "        self.fc1 = nn.Linear(28*28, 512)   # Input: 28x28 image, Hidden layer: 512 neurons\n",
    "        self.fc2 = nn.Linear(512, 10)     # Output: 10 classes (digits 0-9)\n",
    "  \n",
    "    def forward(self, x):                 # specifies how the input data flows through the network layers.\n",
    "        x = x.view(-1, 28*28)             # Flatten the image (Removes some of the dimensions)\n",
    "        x = F.relu(self.fc1(x))         # May not always be the same. ReLU is reliable. \n",
    "        x = self.fc2(x)                #   Passes the output from the previous layer to the second fully connected layer fc2\n",
    "        return x                      #   Returns the final output of the network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initilize the model\n",
    "model = Net()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the loss function\n",
    "criterion = nn.CrossEntropyLoss() # BCEWithLogitsLoss could be used as well. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the optimizer function (Brett used \"Adam\") # could use SGD as well. \n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0: Loss: 0.1448\n",
      "Epoch 1: Loss: 0.0311\n",
      "Epoch 2: Loss: 0.0391\n",
      "Epoch 3: Loss: 0.0193\n",
      "Epoch 4: Loss: 0.0075\n",
      "Epoch 5: Loss: 0.0761\n",
      "Epoch 6: Loss: 0.0200\n",
      "Epoch 7: Loss: 0.0181\n",
      "Epoch 8: Loss: 0.0001\n",
      "Epoch 9: Loss: 0.0005\n"
     ]
    }
   ],
   "source": [
    "# Define the training loop then and print the progress for the loop either every epoch or every 5 or 10 epochs. \n",
    "for epoch in range(10): # where I left off @ me\n",
    "    for batch_idx, (data, target) in enumerate(train_loader):\n",
    "        optimizer.zero_grad()\n",
    "        output = model(data)\n",
    "        loss = criterion(output, target)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    #the song says \"print out whats happening\"\n",
    "    print(f'Epoch {epoch}: Loss: {loss.item():.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss: 0.0012, Accuracy: 98.03%\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model with the \".eval()\" function\n",
    "# Calulate the avergae loss and accuracy and print out the results\n",
    "model.eval()  # Set the model to evaluation mode\n",
    "test_loss = 0\n",
    "correct = 0\n",
    "with torch.no_grad():  # No gradients needed during evaluation\n",
    "    for data, target in test_loader:\n",
    "        output = model(data)\n",
    "        test_loss += criterion(output, target).item()\n",
    "        pred = output.argmax(dim=1, keepdim=True)\n",
    "        correct += pred.eq(target.view_as(pred)).sum().item()\n",
    "\n",
    "test_loss /= len(test_loader.dataset)\n",
    "accuracy = 100. * correct / len(test_loader.dataset)\n",
    "\n",
    "print(f'Test Loss: {test_loss:.4f}, Accuracy: {accuracy:.2f}%')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
